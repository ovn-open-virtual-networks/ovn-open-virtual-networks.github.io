<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Bamai Cloud/AI Infra Status</title>
    <link>https://blog.bamaicloud.com/posts/</link>
    <description>Recent content in Posts on Bamai Cloud/AI Infra Status</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Dec 2024 23:22:53 -0500</lastBuildDate>
    <atom:link href="https://blog.bamaicloud.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2024-12-11 OpenAI Kubernetes 故障解析复盘</title>
      <link>https://blog.bamaicloud.com/posts/2024-12-11-openai-kubernetes/</link>
      <pubDate>Fri, 20 Dec 2024 23:22:53 -0500</pubDate>
      <guid>https://blog.bamaicloud.com/posts/2024-12-11-openai-kubernetes/</guid>
      <description>&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;本文主要结合 OpenAI 此次故障和作者工作经验编写。&lt;/em&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://status.openai.com/incidents/ctrsv3lwd797&#34;&gt;OpenAI Incidents https://status.openai.com/incidents/ctrsv3lwd797&lt;/a&gt; 详细记录了 2024 年 12 月 11 日发生的一次故障，当时所有 OpenAI 服务均出现了严重的停机问题。故障的触发源于部署了新的遥测服务（telemetry service），意外导致 Kubernetes 控制平面负载过重，从而引发关键系统的连锁故障。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;This post-mortem details an incident that occurred on December 11, 2024, where all OpenAI services experienced significant downtime. The issue stemmed from a new telemetry service deployment that unintentionally overwhelmed the Kubernetes control plane, causing cascading failures across critical systems. In this post, we break down the root cause, outline the steps taken for remediation, and share the measures we are implementing to prevent similar incidents in the future.&lt;/p&gt;</description>
    </item>
    <item>
      <title>2024-04-08 腾讯云API服务故障解析复盘</title>
      <link>https://blog.bamaicloud.com/posts/2024-04-08-tencent-cloud-api-incident/</link>
      <pubDate>Mon, 15 Apr 2024 22:52:57 -0500</pubDate>
      <guid>https://blog.bamaicloud.com/posts/2024-04-08-tencent-cloud-api-incident/</guid>
      <description>&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;&#xA;&lt;p&gt;2024年04月08日15:23，腾讯云团队收到监控告警，出现大面积登录不了腾讯云控制台故障。&lt;a href=&#34;https://cloud.tencent.com/developer/article/2408984&#34;&gt;腾讯云4月8日故障复盘及情况说明&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;影响&#34;&gt;影响&lt;/h2&gt;&#xA;&lt;p&gt;依赖云API服务的部分公有云服务无法使用，比如云函数、文字识别、微服务平台、音频内容安全、验证码等。此次故障一共持续了近87分钟，期间共有1957个客户报障。&lt;/p&gt;&#xA;&lt;h2 id=&#34;根因&#34;&gt;根因&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;本次API升级过程中，由于新版本的接口协议发生了变化，在后台发布新版本之后对于旧版本前端传来的数据处理逻辑异常，导致生成了一条错误的配置数据，由于灰度机制不足导致异常数据快速扩散到了全网地域，造成整体API使用异常。&lt;/li&gt;&#xA;&lt;li&gt;发生故障后，按照标准回滚方案将服务后台和配置数据同时回滚到旧版本，并重启API后台服务，但此时因为承载API服务的容器平台也依赖API服务才能提供调度能力，即发生了循环依赖，导致服务无法自动拉起。通过运维手工启动方式才使API服务重启，完成整个故障恢复。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;故障修复&#34;&gt;故障修复&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;15:23 监测到故障，立即执行服务的恢复，同时进行原因的排查；&lt;br&gt;&#xA;15:47 发现通过回滚版本没能完全恢复服务，进一步定位问题；&lt;br&gt;&#xA;15:57 定位出故障根因是配置数据出现错误，紧急设计数据修复方案；&lt;br&gt;&#xA;16:02 对全地域进行数据修复工作，API服务逐地域恢复中；&lt;br&gt;&#xA;16:05 观测到除上海外的地域API服务均已恢复，进一步定位上海地域的恢复问题；&lt;br&gt;&#xA;16:25 定位到上海的技术组件存在API循环依赖问题，决定通过流量调度至其他地域来恢复；&lt;br&gt;&#xA;16:45 观测到上海地域恢复了，此时API和依赖API的PaaS服务彻底恢复，但控制台流量剧增，按九倍容量进行了扩容；&lt;br&gt;&#xA;16:50 请求量逐渐恢复到正常水平，业务稳定运行，控制台服务全部恢复；&lt;br&gt;&#xA;17:45 持续观察一小时，未发现问题，按预案处理过程完毕。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;预防措施&#34;&gt;预防措施&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;官方虽然给出了后续的改进措施，但根据作者的一些理解，改进还远远不够。下面是作者的一些思索：&lt;/em&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;灰度验证&lt;/strong&gt; 完善灰度验证策略，后续所有的变更均应该在预发环境或者沙箱环境对变更内容进行严格验证。实施灰度发布策略，逐步推广新功能或配置更改，按集群、可用区、地域逐步生效，以便在发现问题时能够迅速回滚。引入异常自动熔断机制，当检测到系统异常时，能够立即中断变更过程。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;循环依赖&lt;/strong&gt; 优化服务部署架构，通过分层架构、代码审查和监控等手段，避免API服务中潜在的循环依赖问题。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;故障注入&lt;/strong&gt; 定期执行预定的变更策略模拟演练，确保在真实故障发生时，能够迅速切换到恢复模式，最小化服务中断时间&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;统一架构&lt;/strong&gt; 所有集群，可用区，地域在技术架构上应保持一致。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;API 前后兼容性&lt;/strong&gt; 无论是版本升级或回退都应该考虑API兼容性，避免因数据处理不一致导致整个集群不可用。如2023年滴滴机房故障，根因kubernetes 升级到新版本后，又不慎部署了旧版本导致数据处理不兼容最终所有容器重建。&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>2022-12-18 阿里云香港机房服务中断故障解析复盘</title>
      <link>https://blog.bamaicloud.com/posts/2022-12-18-alibaba-hongkong-region-incident/</link>
      <pubDate>Mon, 01 Apr 2024 21:17:43 -0500</pubDate>
      <guid>https://blog.bamaicloud.com/posts/2022-12-18-alibaba-hongkong-region-incident/</guid>
      <description>&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.aliyun.com/noticelist/articleid/1061819219.html&#34;&gt;关于阿里云香港Region可用区C服务中断事件的说明&lt;/a&gt; 2022年12月18日阿里云香港可用区C因机房制冷系统出现故障，导致该可用区服务不可用。&lt;/p&gt;&#xA;&lt;h2 id=&#34;影响&#34;&gt;影响&lt;/h2&gt;&#xA;&lt;p&gt;具体受影响服务包括：云服务器ECS、云数据库、存储产品（对象存储、表格存储等）、云网络产品（全球加速、NAT网关、VPN网关等）等云产品使用。&lt;/p&gt;&#xA;&lt;h2 id=&#34;根因&#34;&gt;根因&lt;/h2&gt;&#xA;&lt;p&gt;机房制冷系统出现异常，导致服务器不可用。&lt;/p&gt;&#xA;&lt;h2 id=&#34;故障修复&#34;&gt;故障修复&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;08:56 阿里云监控到香港Region可用区C机房包间通道温控告警，阿里云工程师介入应急处理，通知机房服务商进行现场排查。&lt;/li&gt;&#xA;&lt;li&gt;09:01 阿里云监控到该机房多个包间温升告警，此时工程师排查到冷机异常。&lt;/li&gt;&#xA;&lt;li&gt;09:09 机房服务商按应急预案对异常冷机进行4+4主备切换以及重启，但操作失败，冷水机组无法恢复正常。&lt;/li&gt;&#xA;&lt;li&gt;09:17 依照故障处理流程，启动制冷异常应急预案，进行辅助散热和应急通风。尝试对冷机控制系统逐个进行隔离和手工恢复操作，但发现无法稳定运行，联系冷机设备供应商到现场排查。此时，由于高温原因，部分服务器开始受到影响。&lt;/li&gt;&#xA;&lt;li&gt;10:30开始 为避免可能出现的高温消防问题，阿里云工程师陆续对整个机房计算、存储、网络、数据库、大数据集群进行降载处理。期间，继续多次对冷机设备进行操作，但均不能保持稳定运行。&lt;/li&gt;&#xA;&lt;li&gt;12:30 冷机设备供应商到场，在多方工程师诊断下，对冷塔、冷却水管路及冷机冷凝器进行手工补水排气操作，但系统仍然无法保持稳定运行。阿里云工程师对部分高温包间启动服务器关机操作。&lt;/li&gt;&#xA;&lt;li&gt;14:47 冷机设备供应商对设备问题排查遇到困难，其中一个包间因高温触发了强制消防喷淋。&lt;/li&gt;&#xA;&lt;li&gt;15:20 冷机设备商工程师现场手工调整配置，冷机群控解锁完成并独立运行，第1台冷机恢复正常，温度开始下降。工程师随后继续通过相同方法对其他冷机进行操作。&lt;/li&gt;&#xA;&lt;li&gt;18:55 4台冷机恢复到正常制冷量。&lt;/li&gt;&#xA;&lt;li&gt;19:02 分批启动服务器，并持续观察温升情况。&lt;/li&gt;&#xA;&lt;li&gt;19:47 机房温度趋于稳定。同时，阿里云工程师开始进行服务启动恢复，并进行必要的数据完整性检查。&lt;/li&gt;&#xA;&lt;li&gt;21:36 大部分机房包间服务器陆续启动并完成检查，机房温度稳定。其中一个包间因消防喷淋启动，未进行服务器上电。因为保持数据的完整性至关重要，工程师对这个包间的服务器进行了仔细的数据安全检查，这里花费了一些必要的时间。&lt;/li&gt;&#xA;&lt;li&gt;22:50 数据检查以及风险评估完成，最后一个包间依据安全性逐步进行供电恢复和服务器启动。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;预防措施&#34;&gt;预防措施&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;冷机系统故障恢复时间过长&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;原因分析&lt;/strong&gt;：机房冷却系统缺水进气形成气阻，影响水路循环导致4台主冷机服务异常，启动4台备冷机时因主备共用的水路循环系统气阻导致启动失败。水盘补水后，因机房冷却系统的群控逻辑，无法单台独立启动冷机，手工修改冷机配置，将冷机从群控调整为独立运行后，陆续启动冷机，影响了冷却系统的恢复时长。整个过程中，原因定位耗时3小时34分钟，补水排气耗时2小时57分钟，解锁群控逻辑启动4台冷机耗时3小时32分钟。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;改进措施&lt;/strong&gt;：全面检查机房基础设施管控系统，在监控数据采集层面，扩大覆盖度，提升精细度，提高对故障的排查和定位速度；在设施管控逻辑层面，确保系统自动切换逻辑符合预期，同时保证手工切换的准确性，防止内部状态死锁从而影响故障的恢复。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;现场处置不及时导致触发消防喷淋&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;原因分析&lt;/strong&gt;：随着机房冷却系统失效，包间温度逐渐升高，导致一机房包间温度达到临界值触发消防系统喷淋，电源柜和多列机柜进水，部分机器硬件损坏，增加了后续恢复难度和时长。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;改进措施&lt;/strong&gt;：加强机房服务商管理，梳理机房温升预案及标准化执行动作，明确温升场景下的业务侧关机和机房强制关电的预案，力求更简单有效，并通过常态化演练强化执行。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;客户在香港地域新购ECS等管控操作失败&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;原因分析&lt;/strong&gt;：ECS管控系统为B、C可用区双机房容灾，C可用区故障后由B可用区对外提供服务，由于大量可用区C的客户在香港其他可用区新购实例，同时可用区C的ECS实例拉起恢复动作引入的流量，导致可用区 B 管控服务资源不足。新扩容的ECS管控系统启动时依赖的中间件服务部署在可用区C机房，导致较长时间内无法扩容。ECS管控依赖的自定义镜像数据服务，依赖可用区C的单AZ冗余版本的OSS服务，导致客户新购实例后出现启动失败的现象。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;改进措施&lt;/strong&gt;：全网巡检，整体优化多AZ产品高可用设计，避免出现依赖OSS单AZ和中间件单AZ的问题。加强阿里云管控平面的容灾演练，进一步提升云产品高可用容灾逃逸能力。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/blockquote&gt;</description>
    </item>
  </channel>
</rss>
